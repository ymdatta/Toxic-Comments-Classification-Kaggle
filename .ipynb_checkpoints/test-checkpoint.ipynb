{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "f03f935e7a4471af4c2ace9a27edbae8172aecfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sumanth\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\users\\sumanth\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import nltk\n",
    "import sklearn\n",
    "import re, string\n",
    "#from sets import Set\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_union\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "edbdafec964e720ad52b7e7e14f85886fc568c59"
   },
   "outputs": [],
   "source": [
    "def remove_big_words(words):\n",
    "    l = []\n",
    "    for word in words:\n",
    "        if len(word) <= 100:\n",
    "            l.append(word)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "92f65cc73759e2d8bb6ca01a6471fe27bf13c226"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_comment( raw_review ):\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    #letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    words = review_text.lower()  \n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words=re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",\"\",words)\n",
    "    #removing usernames\n",
    "    words=re.sub(\"\\[\\[.*\\]\",\"\",words)\n",
    "    words = words.split()     \n",
    "\n",
    "    snowball_stemmer = SnowballStemmer(\"english\")\n",
    "    meaningful_words = [snowball_stemmer.stem(word) for word in words]\n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e6aa7e5b3c8859bda0575bcf9180a6e154664b2f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "b9814580d2b59c0d393316ad0dd8ef5096d7c9b0"
   },
   "outputs": [],
   "source": [
    "\n",
    "df2 = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c78b15d3a09601aa91faa9a1e135a5b5eaa8c23a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149571\n"
     ]
    }
   ],
   "source": [
    "num_reviews = df['comment_text'].size\n",
    "print(num_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0331447e9602237bbbacaadf3d7db9904cf8ece"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "5d6045b885a93c99a397d7fe9636d22f0148ebc6"
   },
   "outputs": [],
   "source": [
    "cleaned_reviews1 = []\n",
    "test_reviews1 = []\n",
    "ltr = df[\"comment_text\"].tolist()\n",
    "lte = df2[\"comment_text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "697318770e280fe9b7aa7620ad9671aea784a8d1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sumanth\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://finance.yahoo.com/news/7-fascinating-nuggets-another-bewildering-150348488.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "c:\\users\\sumanth\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.haaretz.com/news/diplomacy-defense/2-279-calories-per-person-how-israel-made-sure-gaza-didn-t-starve.premium-1.470419\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "c:\\users\\sumanth\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia_talk:No_original_research/archive15#YouTube_art_as_primary_source\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "c:\\users\\sumanth\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://en.wikipedia.org/wiki/Wikipedia:ELYES\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "cleaned_reviews = []\n",
    "test_reviews = []\n",
    "#for i in range(0, num_reviews):\n",
    "#    #cleaning reviews using the above function\n",
    "#    cleaned_reviews.append(clean_comment(df['comment_text'][i]))\n",
    "\n",
    "num_test_reviews = df2['comment_text'].size\n",
    "print(num_test_reviews)\n",
    "\n",
    "for i in range(0, num_test_reviews):\n",
    "    test_reviews.append(clean_comment(df2['comment_text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open( \"vectorizer\" + \".pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "2120428ecb7f39a6ebbd40495ce3c1129de86165"
   },
   "outputs": [
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f593a3531e0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/mohanadatta/.local/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/mohana.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f593a3531e0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/mohanadatta/.local/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/mohana.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    492         if self.poller is not None:\n    493             self.poller.start()\n    494         self.kernel.start()\n    495         self.io_loop = ioloop.IOLoop.current()\n    496         try:\n--> 497             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    498         except KeyboardInterrupt:\n    499             pass\n    500 \n    501 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\n/usr/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    422             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    423                                    finalizer=self._asyncgen_finalizer_hook)\n    424         try:\n    425             events._set_running_loop(self)\n    426             while True:\n--> 427                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    428                 if self._stopping:\n    429                     break\n    430         finally:\n    431             self._stopping = False\n\n...........................................................................\n/usr/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1435                         logger.warning('Executing %s took %.3f seconds',\n   1436                                        _format_handle(handle), dt)\n   1437                 finally:\n   1438                     self._current_handle = None\n   1439             else:\n-> 1440                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(14, 1)>>\n   1441         handle = None  # Needed to break cycles when an exception occurs.\n   1442 \n   1443     def _set_coroutine_wrapper(self, enabled):\n   1444         try:\n\n...........................................................................\n/usr/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(14, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (14, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=14, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 7, 18, 50, 24, 495669, tzinfo=tzutc()), 'msg_id': 'f2d4f81236364dd398870bff730a3bf1', 'msg_type': 'execute_request', 'session': '58ddd28e12aa455482265cf6db97ece3', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f2d4f81236364dd398870bff730a3bf1', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'58ddd28e12aa455482265cf6db97ece3']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 7, 18, 50, 24, 495669, tzinfo=tzutc()), 'msg_id': 'f2d4f81236364dd398870bff730a3bf1', 'msg_type': 'execute_request', 'session': '58ddd28e12aa455482265cf6db97ece3', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f2d4f81236364dd398870bff730a3bf1', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'58ddd28e12aa455482265cf6db97ece3'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 7, 18, 50, 24, 495669, tzinfo=tzutc()), 'msg_id': 'f2d4f81236364dd398870bff730a3bf1', 'msg_type': 'execute_request', 'session': '58ddd28e12aa455482265cf6db97ece3', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f2d4f81236364dd398870bff730a3bf1', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>], cell_name='<ipython-input-8-d29b84256ef9>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f58e8ffbb70, executi...rue silent=False shell_futures=True> result=None>)\n   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n   2897         try:\n   2898             for i, node in enumerate(to_run_exec):\n   2899                 mod = ast.Module([node])\n   2900                 code = compiler(mod, cell_name, \"exec\")\n-> 2901                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f58e3efc300, file \"<ipython-input-8-d29b84256ef9>\", line 1>\n        result = <ExecutionResult object at 7f58e8ffbb70, executi...rue silent=False shell_futures=True> result=None>\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f58e3efc300, file \"<ipython-input-8-d29b84256ef9>\", line 1>, result=<ExecutionResult object at 7f58e8ffbb70, executi...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f58e3efc300, file \"<ipython-input-8-d29b84256ef9>\", line 1>\n        self.user_global_ns = {'BeautifulSoup': <class 'bs4.BeautifulSoup'>, 'Counter': <class 'collections.Counter'>, 'In': ['', 'from sklearn.feature_extraction.text import Tfid...B\\nfrom nltk.stem.wordnet import WordNetLemmatizer', 'def remove_big_words(words):\\n    l = []\\n    for ...) <= 100:\\n            l.append(word)\\n    return l', 'import nltk\\nfrom nltk.stem import WordNetLemmati...result.\\n    return( \" \".join( meaningful_words ))', \"df = pd.read_csv('train.csv')\\ndf2 = pd.read_csv('test.csv')\\n#print(df.head)\", \"num_reviews = df['comment_text'].size\\nprint(num_reviews)\", 'cleaned_reviews1 = []\\ntest_reviews1 = []\\nltr = d...ext\"].tolist()\\nlte = df2[\"comment_text\"].tolist()', 'cleaned_reviews = []\\ntest_reviews = []\\nfor i in ...union(word_vectorizer, char_vectorizer, n_jobs=2)', 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)'], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {}, 'PorterStemmer': <class 'nltk.stem.porter.PorterStemmer'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'BeautifulSoup': <class 'bs4.BeautifulSoup'>, 'Counter': <class 'collections.Counter'>, 'In': ['', 'from sklearn.feature_extraction.text import Tfid...B\\nfrom nltk.stem.wordnet import WordNetLemmatizer', 'def remove_big_words(words):\\n    l = []\\n    for ...) <= 100:\\n            l.append(word)\\n    return l', 'import nltk\\nfrom nltk.stem import WordNetLemmati...result.\\n    return( \" \".join( meaningful_words ))', \"df = pd.read_csv('train.csv')\\ndf2 = pd.read_csv('test.csv')\\n#print(df.head)\", \"num_reviews = df['comment_text'].size\\nprint(num_reviews)\", 'cleaned_reviews1 = []\\ntest_reviews1 = []\\nltr = d...ext\"].tolist()\\nlte = df2[\"comment_text\"].tolist()', 'cleaned_reviews = []\\ntest_reviews = []\\nfor i in ...union(word_vectorizer, char_vectorizer, n_jobs=2)', 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)'], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {}, 'PorterStemmer': <class 'nltk.stem.porter.PorterStemmer'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\n/home/mohanadatta/sem5/ML/IMT2016012_IMT2016120_IMT2016081/<ipython-input-8-d29b84256ef9> in <module>()\n----> 1 rev_vecs = vectorizer.fit_transform(cleaned_reviews)\n      2 sub1_vecs = vectorizer.transform(test_reviews)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=2,\n       transformer_list=[...abulary=None))],\n       transformer_weights=None), X=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None, **fit_params={})\n    734         \"\"\"\n    735         self._validate_transformers()\n    736         result = Parallel(n_jobs=self.n_jobs)(\n    737             delayed(_fit_transform_one)(trans, weight, X, y,\n    738                                         **fit_params)\n--> 739             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion...bulary=None))],\n       transformer_weights=None)>\n    740 \n    741         if not result:\n    742             # All transformers are None\n    743             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Sat Dec  8 00:22:40 2018\nPID: 5022                                    Python 3.6.7: /usr/bin/python3\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_transform_one>, (TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), None, [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], None), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), None, [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], None)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), weight=None, X=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        X = [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...]\n        y = None\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None)\n   1376         Returns\n   1377         -------\n   1378         X : sparse matrix, [n_samples, n_features]\n   1379             Tf-idf-weighted document-term matrix.\n   1380         \"\"\"\n-> 1381         X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n        X = undefined\n        self.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        raw_documents = [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...]\n   1382         self._tfidf.fit(X)\n   1383         # X is already a transformed view of raw_documents so\n   1384         # we set copy to False\n   1385         return self._tfidf.transform(X, copy=False)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None)\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n    874         if not self.fixed_vocabulary_:\n--> 875             X = self._sort_features(X, vocabulary)\n        X = <149571x574495 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        self._sort_features = <bound method CountVectorizer._sort_features of ...zer=None, use_idf=True,\n        vocabulary=None)>\n        vocabulary = {' ': 0, ' !': 1, ' ! ': 2, ' ! !': 3, ' ! \"': 4, \" ! '\": 5, ' ! (': 6, ' ! )': 7, ' ! ,': 8, ' ! -': 9, ...}\n    876 \n    877             n_doc = X.shape[0]\n    878             max_doc_count = (max_df\n    879                              if isinstance(max_df, numbers.Integral)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in _sort_features(self=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), X=<149571x574495 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, vocabulary={' ': 0, ' !': 1, ' ! ': 2, ' ! !': 3, ' ! \"': 4, \" ! '\": 5, ' ! (': 6, ' ! )': 7, ' ! ,': 8, ' ! -': 9, ...})\n    726         map_index = np.empty(len(sorted_features), dtype=np.int32)\n    727         for new_val, (term, old_val) in enumerate(sorted_features):\n    728             vocabulary[term] = new_val\n    729             map_index[old_val] = new_val\n    730 \n--> 731         X.indices = map_index.take(X.indices, mode='clip')\n        X.indices = array([    0,     1,     2, ..., 62569, 62570, 89545], dtype=int32)\n        map_index.take = <built-in method take of numpy.ndarray object>\n    732         return X\n    733 \n    734     def _limit_features(self, X, vocabulary, high=None, low=None,\n    735                         limit=None):\n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/pipeline.py\", line 581, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 1381, in fit_transform\n    X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n  File \"/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 875, in fit_transform\n    X = self._sort_features(X, vocabulary)\n  File \"/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 731, in _sort_features\n    X.indices = map_index.take(X.indices, mode='clip')\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nMemoryError                                        Sat Dec  8 00:22:40 2018\nPID: 5022                                    Python 3.6.7: /usr/bin/python3\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_transform_one>, (TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), None, [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], None), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), None, [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], None)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), weight=None, X=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        X = [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...]\n        y = None\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None)\n   1376         Returns\n   1377         -------\n   1378         X : sparse matrix, [n_samples, n_features]\n   1379             Tf-idf-weighted document-term matrix.\n   1380         \"\"\"\n-> 1381         X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n        X = undefined\n        self.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        raw_documents = [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...]\n   1382         self._tfidf.fit(X)\n   1383         # X is already a transformed view of raw_documents so\n   1384         # we set copy to False\n   1385         return self._tfidf.transform(X, copy=False)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None)\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n    874         if not self.fixed_vocabulary_:\n--> 875             X = self._sort_features(X, vocabulary)\n        X = <149571x574495 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        self._sort_features = <bound method CountVectorizer._sort_features of ...zer=None, use_idf=True,\n        vocabulary=None)>\n        vocabulary = {' ': 0, ' !': 1, ' ! ': 2, ' ! !': 3, ' ! \"': 4, \" ! '\": 5, ' ! (': 6, ' ! )': 7, ' ! ,': 8, ' ! -': 9, ...}\n    876 \n    877             n_doc = X.shape[0]\n    878             max_doc_count = (max_df\n    879                              if isinstance(max_df, numbers.Integral)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in _sort_features(self=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), X=<149571x574495 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, vocabulary={' ': 0, ' !': 1, ' ! ': 2, ' ! !': 3, ' ! \"': 4, \" ! '\": 5, ' ! (': 6, ' ! )': 7, ' ! ,': 8, ' ! -': 9, ...})\n    726         map_index = np.empty(len(sorted_features), dtype=np.int32)\n    727         for new_val, (term, old_val) in enumerate(sorted_features):\n    728             vocabulary[term] = new_val\n    729             map_index[old_val] = new_val\n    730 \n--> 731         X.indices = map_index.take(X.indices, mode='clip')\n        X.indices = array([    0,     1,     2, ..., 62569, 62570, 89545], dtype=int32)\n        map_index.take = <built-in method take of numpy.ndarray object>\n    732         return X\n    733 \n    734     def _limit_features(self, X, vocabulary, high=None, low=None,\n    735                         limit=None):\n\nMemoryError: \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nMemoryError                                        Sat Dec  8 00:22:40 2018\nPID: 5022                                    Python 3.6.7: /usr/bin/python3\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_transform_one>, (TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), None, [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], None), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), None, [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], None)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), weight=None, X=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        X = [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...]\n        y = None\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None)\n   1376         Returns\n   1377         -------\n   1378         X : sparse matrix, [n_samples, n_features]\n   1379             Tf-idf-weighted document-term matrix.\n   1380         \"\"\"\n-> 1381         X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n        X = undefined\n        self.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        raw_documents = [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...]\n   1382         self._tfidf.fit(X)\n   1383         # X is already a transformed view of raw_documents so\n   1384         # we set copy to False\n   1385         return self._tfidf.transform(X, copy=False)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None)\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n    874         if not self.fixed_vocabulary_:\n--> 875             X = self._sort_features(X, vocabulary)\n        X = <149571x574495 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        self._sort_features = <bound method CountVectorizer._sort_features of ...zer=None, use_idf=True,\n        vocabulary=None)>\n        vocabulary = {' ': 0, ' !': 1, ' ! ': 2, ' ! !': 3, ' ! \"': 4, \" ! '\": 5, ' ! (': 6, ' ! )': 7, ' ! ,': 8, ' ! -': 9, ...}\n    876 \n    877             n_doc = X.shape[0]\n    878             max_doc_count = (max_df\n    879                              if isinstance(max_df, numbers.Integral)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in _sort_features(self=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), X=<149571x574495 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, vocabulary={' ': 0, ' !': 1, ' ! ': 2, ' ! !': 3, ' ! \"': 4, \" ! '\": 5, ' ! (': 6, ' ! )': 7, ' ! ,': 8, ' ! -': 9, ...})\n    726         map_index = np.empty(len(sorted_features), dtype=np.int32)\n    727         for new_val, (term, old_val) in enumerate(sorted_features):\n    728             vocabulary[term] = new_val\n    729             map_index[old_val] = new_val\n    730 \n--> 731         X.indices = map_index.take(X.indices, mode='clip')\n        X.indices = array([    0,     1,     2, ..., 62569, 62570, 89545], dtype=int32)\n        map_index.take = <built-in method take of numpy.ndarray object>\n    732         return X\n    733 \n    734     def _limit_features(self, X, vocabulary, high=None, low=None,\n    735                         limit=None):\n\nMemoryError: \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d29b84256ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrev_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msub1_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             delayed(_fit_transform_one)(trans, weight, X, y,\n\u001b[1;32m    738\u001b[0m                                         **fit_params)\n\u001b[0;32m--> 739\u001b[0;31m             for name, trans, weight in self._iter())\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f593a3531e0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/mohanadatta/.local/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/mohana.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f593a3531e0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/mohanadatta/.local/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/mohana.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    492         if self.poller is not None:\n    493             self.poller.start()\n    494         self.kernel.start()\n    495         self.io_loop = ioloop.IOLoop.current()\n    496         try:\n--> 497             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    498         except KeyboardInterrupt:\n    499             pass\n    500 \n    501 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\n/usr/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    422             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    423                                    finalizer=self._asyncgen_finalizer_hook)\n    424         try:\n    425             events._set_running_loop(self)\n    426             while True:\n--> 427                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    428                 if self._stopping:\n    429                     break\n    430         finally:\n    431             self._stopping = False\n\n...........................................................................\n/usr/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1435                         logger.warning('Executing %s took %.3f seconds',\n   1436                                        _format_handle(handle), dt)\n   1437                 finally:\n   1438                     self._current_handle = None\n   1439             else:\n-> 1440                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(14, 1)>>\n   1441         handle = None  # Needed to break cycles when an exception occurs.\n   1442 \n   1443     def _set_coroutine_wrapper(self, enabled):\n   1444         try:\n\n...........................................................................\n/usr/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(14, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (14, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=14, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 7, 18, 50, 24, 495669, tzinfo=tzutc()), 'msg_id': 'f2d4f81236364dd398870bff730a3bf1', 'msg_type': 'execute_request', 'session': '58ddd28e12aa455482265cf6db97ece3', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f2d4f81236364dd398870bff730a3bf1', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'58ddd28e12aa455482265cf6db97ece3']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 7, 18, 50, 24, 495669, tzinfo=tzutc()), 'msg_id': 'f2d4f81236364dd398870bff730a3bf1', 'msg_type': 'execute_request', 'session': '58ddd28e12aa455482265cf6db97ece3', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f2d4f81236364dd398870bff730a3bf1', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'58ddd28e12aa455482265cf6db97ece3'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 7, 18, 50, 24, 495669, tzinfo=tzutc()), 'msg_id': 'f2d4f81236364dd398870bff730a3bf1', 'msg_type': 'execute_request', 'session': '58ddd28e12aa455482265cf6db97ece3', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f2d4f81236364dd398870bff730a3bf1', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>], cell_name='<ipython-input-8-d29b84256ef9>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f58e8ffbb70, executi...rue silent=False shell_futures=True> result=None>)\n   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n   2897         try:\n   2898             for i, node in enumerate(to_run_exec):\n   2899                 mod = ast.Module([node])\n   2900                 code = compiler(mod, cell_name, \"exec\")\n-> 2901                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f58e3efc300, file \"<ipython-input-8-d29b84256ef9>\", line 1>\n        result = <ExecutionResult object at 7f58e8ffbb70, executi...rue silent=False shell_futures=True> result=None>\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f58e3efc300, file \"<ipython-input-8-d29b84256ef9>\", line 1>, result=<ExecutionResult object at 7f58e8ffbb70, executi...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f58e3efc300, file \"<ipython-input-8-d29b84256ef9>\", line 1>\n        self.user_global_ns = {'BeautifulSoup': <class 'bs4.BeautifulSoup'>, 'Counter': <class 'collections.Counter'>, 'In': ['', 'from sklearn.feature_extraction.text import Tfid...B\\nfrom nltk.stem.wordnet import WordNetLemmatizer', 'def remove_big_words(words):\\n    l = []\\n    for ...) <= 100:\\n            l.append(word)\\n    return l', 'import nltk\\nfrom nltk.stem import WordNetLemmati...result.\\n    return( \" \".join( meaningful_words ))', \"df = pd.read_csv('train.csv')\\ndf2 = pd.read_csv('test.csv')\\n#print(df.head)\", \"num_reviews = df['comment_text'].size\\nprint(num_reviews)\", 'cleaned_reviews1 = []\\ntest_reviews1 = []\\nltr = d...ext\"].tolist()\\nlte = df2[\"comment_text\"].tolist()', 'cleaned_reviews = []\\ntest_reviews = []\\nfor i in ...union(word_vectorizer, char_vectorizer, n_jobs=2)', 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)'], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {}, 'PorterStemmer': <class 'nltk.stem.porter.PorterStemmer'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'BeautifulSoup': <class 'bs4.BeautifulSoup'>, 'Counter': <class 'collections.Counter'>, 'In': ['', 'from sklearn.feature_extraction.text import Tfid...B\\nfrom nltk.stem.wordnet import WordNetLemmatizer', 'def remove_big_words(words):\\n    l = []\\n    for ...) <= 100:\\n            l.append(word)\\n    return l', 'import nltk\\nfrom nltk.stem import WordNetLemmati...result.\\n    return( \" \".join( meaningful_words ))', \"df = pd.read_csv('train.csv')\\ndf2 = pd.read_csv('test.csv')\\n#print(df.head)\", \"num_reviews = df['comment_text'].size\\nprint(num_reviews)\", 'cleaned_reviews1 = []\\ntest_reviews1 = []\\nltr = d...ext\"].tolist()\\nlte = df2[\"comment_text\"].tolist()', 'cleaned_reviews = []\\ntest_reviews = []\\nfor i in ...union(word_vectorizer, char_vectorizer, n_jobs=2)', 'rev_vecs = vectorizer.fit_transform(cleaned_reviews)\\nsub1_vecs = vectorizer.transform(test_reviews)'], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {}, 'PorterStemmer': <class 'nltk.stem.porter.PorterStemmer'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\n/home/mohanadatta/sem5/ML/IMT2016012_IMT2016120_IMT2016081/<ipython-input-8-d29b84256ef9> in <module>()\n----> 1 rev_vecs = vectorizer.fit_transform(cleaned_reviews)\n      2 sub1_vecs = vectorizer.transform(test_reviews)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=2,\n       transformer_list=[...abulary=None))],\n       transformer_weights=None), X=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None, **fit_params={})\n    734         \"\"\"\n    735         self._validate_transformers()\n    736         result = Parallel(n_jobs=self.n_jobs)(\n    737             delayed(_fit_transform_one)(trans, weight, X, y,\n    738                                         **fit_params)\n--> 739             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion...bulary=None))],\n       transformer_weights=None)>\n    740 \n    741         if not result:\n    742             # All transformers are None\n    743             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object FeatureUnion.fit_transform.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Sat Dec  8 00:22:40 2018\nPID: 5022                                    Python 3.6.7: /usr/bin/python3\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_transform_one>, (TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), None, [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], None), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), None, [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], None)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), weight=None, X=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        X = [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...]\n        y = None\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None)\n   1376         Returns\n   1377         -------\n   1378         X : sparse matrix, [n_samples, n_features]\n   1379             Tf-idf-weighted document-term matrix.\n   1380         \"\"\"\n-> 1381         X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n        X = undefined\n        self.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        raw_documents = [\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...]\n   1382         self._tfidf.fit(X)\n   1383         # X is already a transformed view of raw_documents so\n   1384         # we set copy to False\n   1385         return self._tfidf.transform(X, copy=False)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=[\"the troubl with wikipedia is you sad get self ri...!) then perhap you'd take a hike and not pick so.\", 'carri died? it say that carri lee thornton mille...sister, die on 5 jan 2010. where is the citation?', 'lol wtf= how do they make them?? how did they li...egalith in lebanon that is over 10,000 year old..', 'redirect talk:th o₂ (london)', 'imag cold war - chang of border my text was in the talk page of the image, sz', 'exact my point, my friend! unsourc imag should b...v the other unsourc imagery, thank you veri much!', 'comment: i came here from the wikipedia:third op...than that, i think this is overal a good article.', '\" hindu i read the complet page, and could not u...the term \"\"hindu\"\". where and how was it coin ? \"', '\" twilight princess no problem. i was even go to...one. ≠ yeah, a star would be nice, too p (talk) \"', '\" an encyclopedia for you! an encyclopedia for you! it is heavi and like to crush your head. \"', 'kit thank for look at this if you were go to rep... is nice to have our actual club kit on the page.', '\"funny, i clear rememb that you advis peopl to r...or inaccuraci he portrays. thank you. chatnoir. \"', 'would you believ it.. this frenchi threaten to b...is protect by lobbyists. that includ frog eaters.', '\" an admin warn the user not to edit war until m...=user_talk:lukeno94&diff;=prev&oldid;=588610599 \"', 'oh wow a block im so scared.', 'that may be, but keep them so peopl can still lo... was onli to disencourag edit wars, which it has.', 'septemb 2007 pleas stop. if you continu to vanda.... click here for detail of your recent vandalism.', '\" lead i chang the former introductori phrase (\"...t wass, constantin petrovicescu, visarion puiu) \"', \"asid from the municip election, i don't know abo... someth to keep an eye on, should be interesting.\", 'redirect talk:th massacr of rabaa between narrat & document', ...], y=None)\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n    874         if not self.fixed_vocabulary_:\n--> 875             X = self._sort_features(X, vocabulary)\n        X = <149571x574495 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        self._sort_features = <bound method CountVectorizer._sort_features of ...zer=None, use_idf=True,\n        vocabulary=None)>\n        vocabulary = {' ': 0, ' !': 1, ' ! ': 2, ' ! !': 3, ' ! \"': 4, \" ! '\": 5, ' ! (': 6, ' ! )': 7, ' ! ,': 8, ' ! -': 9, ...}\n    876 \n    877             n_doc = X.shape[0]\n    878             max_doc_count = (max_df\n    879                              if isinstance(max_df, numbers.Integral)\n\n...........................................................................\n/home/mohanadatta/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in _sort_features(self=TfidfVectorizer(analyzer='char', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), X=<149571x574495 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, vocabulary={' ': 0, ' !': 1, ' ! ': 2, ' ! !': 3, ' ! \"': 4, \" ! '\": 5, ' ! (': 6, ' ! )': 7, ' ! ,': 8, ' ! -': 9, ...})\n    726         map_index = np.empty(len(sorted_features), dtype=np.int32)\n    727         for new_val, (term, old_val) in enumerate(sorted_features):\n    728             vocabulary[term] = new_val\n    729             map_index[old_val] = new_val\n    730 \n--> 731         X.indices = map_index.take(X.indices, mode='clip')\n        X.indices = array([    0,     1,     2, ..., 62569, 62570, 89545], dtype=int32)\n        map_index.take = <built-in method take of numpy.ndarray object>\n    732         return X\n    733 \n    734     def _limit_features(self, X, vocabulary, high=None, low=None,\n    735                         limit=None):\n\nMemoryError: \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "rev_vecs = vectorizer.fit_transform(cleaned_reviews)\n",
    "sub1_vecs = vectorizer.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f1dd0b8c408630ff1e5e4ea7ff238c0bfd594688"
   },
   "outputs": [],
   "source": [
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult' ,'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f131b7dd2c3c79087268c843a96cdfc9ae3fb17"
   },
   "outputs": [],
   "source": [
    "labels=[]\n",
    "temp=[]\n",
    "print(num_reviews)\n",
    "for i in range(0, num_reviews):\n",
    "    #cleaning reviews using the above function\n",
    "    temp=[df['toxic'][i],df['severe_toxic'][i],df['obscene'][i],df['threat'][i],df['insult'][i],df['identity_hate'][i]]\n",
    "    #print(temp)\n",
    "    labels.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "88e455a0ecf8f6e0a05d43a8f026040dc9318d46"
   },
   "outputs": [],
   "source": [
    "\n",
    "labels = np.asarray(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af4efbca641be16645c9e7a01a436ae7e191c125"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test =   cross_validation.train_test_split(rev_vecs,  labels, test_size=0.00)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af075b93ee1dc631ef2c1a1f81b97750295c0510"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a629b3c590d9fa50a12bbff4124dc108851ab5bf"
   },
   "outputs": [],
   "source": [
    "\n",
    "y_train_t = y_train.T\n",
    "\n",
    "y_test_t = y_test.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6226e0875dc9d78ecb667fdaae34110b5afc8da6"
   },
   "outputs": [],
   "source": [
    "all_parameters = {\n",
    "                  'C'             : [1, 0.2, 0.6, 0.2, 0.45, 0.25],\n",
    "#                   'tol'           : [0.1, 0.1, 0.046, 0.02, 0.1, 0.01],\n",
    "#                  'solver'        : ['lbfgs', 'newton-cg', 'lbfgs', 'newton-cg', 'newton-cg', 'lbfgs'],\n",
    "                  'fit_intercept' : [True, True, True, True, True, True],\n",
    "                  'penalty'       : ['l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
    "                  'class_weight'  : [None, 'balanced', 'balanced', 'balanced', 'balanced', 'balanced'],\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6f5aa7dd0bf2e711f0b8f4ef936da06660f4f93",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "scores = []\n",
    "for index, category in enumerate(categories):\n",
    "    model = pickle.load(open( category + \"_pickle\", \"rb\"))\n",
    "    l.append((classif.predict_proba(sub1_vecs)[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "95aa1ad5bfc592a3c27b72d344a17be2d198e702"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a611bd1fc032e8c35be0f248b214533f33c4d787"
   },
   "outputs": [],
   "source": [
    "id_numbers = list(df2['Id'])\n",
    "temp_2 = ['Id'] + categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d3fe16d0480c6cb4c0908a77a2fc6ede9f038eec"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
